# Job Monitoring System
**ê¸°ì—… ì±„ìš©í™ˆí˜ì´ì§€ ìë™ ëª¨ë‹ˆí„°ë§ ë° Slack ì•Œë¦¼ ì‹œìŠ¤í…œ**

## ëª©ì°¨
- [ì‹œìŠ¤í…œ ê°œìš”](#ì‹œìŠ¤í…œ-ê°œìš”)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
- [ë™ì‘ íë¦„ë„](#ë™ì‘-íë¦„ë„)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#í”„ë¡œì íŠ¸-êµ¬ì¡°)
- [í•µì‹¬ ê¸°ëŠ¥](#í•µì‹¬-ê¸°ëŠ¥)
- [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
- [ìš´ì˜ ê°€ì´ë“œ](#ìš´ì˜-ê°€ì´ë“œ)
- [ê¸°ìˆ  ë¬¸ì„œ](#ê¸°ìˆ -ë¬¸ì„œ)
- [ë¬¸ì œí•´ê²°](#ë¬¸ì œí•´ê²°)

## ì‹œìŠ¤í…œ ê°œìš”

**Job Monitoring System**ì€ ê¸°ì—… ì±„ìš©í™ˆí˜ì´ì§€ë¥¼ ìë™ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§í•˜ì—¬ ìƒˆë¡œìš´ ì±„ìš©ê³µê³ ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•˜ê³  Slackìœ¼ë¡œ ì•Œë¦¼ì„ ë³´ë‚´ëŠ” ì™„ì „ ìë™í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- **ì§€ëŠ¥í˜• í¬ë¡¤ë§**: ë™ì /ì •ì  ì›¹ì‚¬ì´íŠ¸ë¥¼ ìë™ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ìµœì í™”ëœ ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§
- **íŒ¨í„´ ê¸°ë°˜ ì„ íƒì ìƒì„±**: ì±„ìš©ê³µê³  ì˜ì—­ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ëŠ” CSS ì„ íƒì ìƒì„±
- **ëŒ€ìš©ëŸ‰ ì²˜ë¦¬**: 5000ëŒ€ ê¸°ì—…ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ì•ˆì „í•˜ê²Œ ë³‘ë ¬ ì²˜ë¦¬
- **ì‹¤ì‹œê°„ ì•Œë¦¼**: ìƒˆë¡œìš´ ì±„ìš©ê³µê³  ë°œê²¬ ì‹œ Slackìœ¼ë¡œ ì¦‰ì‹œ ì•Œë¦¼
- **ì›¹ ê¸°ë°˜ ê´€ë¦¬**: Google Sheetsë¥¼ í†µí•œ ì¤‘ì•™í™”ëœ ì„¤ì • ê´€ë¦¬

### ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ
| ëŒ€ìƒ | ì‹¤í–‰ ì‹œê°„ | ì²˜ë¦¬ ë°©ì‹ | Slack ì±„ë„ |
|------|----------|----------|------------|
| **ì¼ë°˜ ì±„ìš©í™ˆí˜ì´ì§€** | ë§¤ì¼ 10ì‹œ, 15ì‹œ | ì „ì²´ ì¼ê´„ ì²˜ë¦¬ | `SLACK_WEBHOOK_URL` |
| **5000ëŒ€ ê¸°ì—…** | ë§¤ì¼ 19ì‹œ | 100ê°œì”© ì²­í¬ ì²˜ë¦¬ | `TOP5000COMPANY_URL` |

## ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    A[Airflow Scheduler] --> B{DAG ì„ íƒ}
    B --> C[ì¼ë°˜ ëª¨ë‹ˆí„°ë§ DAG<br/>10ì‹œ, 15ì‹œ]
    B --> D[5000ëŒ€ ê¸°ì—… DAG<br/>19ì‹œ]

    C --> E[JobMonitoringDAG]
    D --> E

    E --> F[Google Sheets<br/>íšŒì‚¬ ëª©ë¡ ë¡œë“œ]
    F --> G[ì „ì²˜ë¦¬ & í¬ë¡¤ë§ í†µí•©]
    G --> H{ì²˜ë¦¬ ë°©ì‹}

    H --> I[ì¼ë°˜: ì „ì²´ ì²˜ë¦¬]
    H --> J[5000ëŒ€: ì²­í¬ ì²˜ë¦¬<br/>100ê°œì”©]

    I --> K[ë¹„êµ & ì•Œë¦¼]
    J --> L[ì²­í¬ë³„ ì²˜ë¦¬]
    L --> M[ì „ì²´ ìš”ì•½ ì•Œë¦¼]

    K --> N[Slack ì•Œë¦¼]
    M --> N
    N --> O[ê²°ê³¼ ì €ì¥]
    O --> P[Google Sheets ë™ê¸°í™”]
```

## ë™ì‘ íë¦„ë„

### 1. ì „ì²´ ì‹œìŠ¤í…œ íë¦„
```
Airflow ìŠ¤ì¼€ì¤„ëŸ¬
    â†“
JobMonitoringDAG ì‹¤í–‰
    â†“
Google Sheets ë°ì´í„° ë¡œë“œ
    â”œâ”€ íšŒì‚¬ ëª©ë¡ (URL, ì„¤ì •)
    â””â”€ ì™¸êµ­ì¸ ì±„ìš© í‚¤ì›Œë“œ
    â†“
í†µí•© ì „ì²˜ë¦¬ & í¬ë¡¤ë§
    â”œâ”€ Selenium í•„ìš”ì„± ìë™ íŒë‹¨
    â”œâ”€ CSS ì„ íƒì ìë™ ìƒì„±/ì¬í™œìš©
    â”œâ”€ ë³‘ë ¬ HTML ìˆ˜ì§‘ (3ê°œ ì›Œì»¤)
    â””â”€ ì±„ìš©ê³µê³  ë°ì´í„° ì¶”ì¶œ
    â†“
ê²°ê³¼ ë¹„êµ & ë¶„ì„
    â”œâ”€ ìƒˆë¡œìš´ ì±„ìš©ê³µê³  ê°ì§€
    â”œâ”€ ì™¸êµ­ì¸ ì±„ìš©ê³µê³  í•„í„°ë§
    â””â”€ ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë³€ê²½ì‚¬í•­ ì²´í¬
    â†“
Slack ì•Œë¦¼ ë°œì†¡
    â”œâ”€ êµ¬ì¡°í™”ëœ ë©”ì‹œì§€ (Block Kit)
    â”œâ”€ íšŒì‚¬ë³„ ê·¸ë£¹í™”
    â”œâ”€ ì™¸êµ­ì¸ ê³µê³  í•˜ì´ë¼ì´íŠ¸
    â””â”€ ì‹œê°„ ì •ë³´ í¬í•¨
    â†“
ê²°ê³¼ ì €ì¥ & ë™ê¸°í™”
    â”œâ”€ CSV íŒŒì¼ ì €ì¥
    â””â”€ Google Sheets ì—…ë°ì´íŠ¸
```

### 2. 5000ëŒ€ ê¸°ì—… ì²­í¬ ì²˜ë¦¬ íë¦„
```
5000ëŒ€_ê¸°ì—… ì‹œíŠ¸ ë¡œë“œ
    â†“
100ê°œì”© ì²­í¬ ë¶„í• 
    â†“
ê° ì²­í¬ë³„ ì²˜ë¦¬ Loop
    â”œâ”€ ì²­í¬ N ì²˜ë¦¬ ì‹œì‘ ë¡œê·¸
    â”œâ”€ í†µí•© ì „ì²˜ë¦¬ & í¬ë¡¤ë§
    â”œâ”€ ì•ˆì „í•œ ì¤‘ê°„ ì €ì¥ (Google Sheets)
    â”œâ”€ ì‹¤íŒ¨ ì •ë³´ ìˆ˜ì§‘ (ì•Œë¦¼ X)
    â”œâ”€ 2ë¶„ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
    â””â”€ ë‹¤ìŒ ì²­í¬ë¡œ ì´ë™
    â†“
ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ í›„
    â”œâ”€ ëª¨ë“  ê²½ê³ ì‚¬í•­ ìˆ˜ì§‘
    â”œâ”€ ëª¨ë“  ì‹¤íŒ¨ ì •ë³´ ìˆ˜ì§‘
    â””â”€ ìš”ì•½ ì•Œë¦¼ í•œë²ˆì— ë°œì†¡
    â†“
ìµœì¢… ì €ì¥ & ë™ê¸°í™”
```

### 3. ê°œë³„ íšŒì‚¬ ì²˜ë¦¬ ìƒì„¸ íë¦„
```
íšŒì‚¬ ì •ë³´ ì…ë ¥
    â”œâ”€ íšŒì‚¬ëª…, URL, ê¸°ì¡´ ì„ íƒì
    â””â”€ selenium_required ê°’
    â†“
Selenium í•„ìš”ì„± ìë™ íŒë‹¨
    â”œâ”€ SPA í”„ë ˆì„ì›Œí¬ ê°ì§€
    â”œâ”€ JavaScript ì˜ì¡´ë„ ë¶„ì„
    â””â”€ íŠ¹ì • ì‚¬ì´íŠ¸ ì˜ˆì™¸ ì²˜ë¦¬
    â†“
HTML ì½˜í…ì¸  ìˆ˜ì§‘
    â”œâ”€ ì •ì : requests (ë¹ ë¥¸ ì²˜ë¦¬)
    â””â”€ ë™ì : Playwright (ë¸Œë¼ìš°ì € ìë™í™”)
    â†“
CSS ì„ íƒì ì²˜ë¦¬
    â”œâ”€ ê¸°ì¡´ ê²€ì¦ëœ ì„ íƒì ì¬í™œìš© (20ì+ ìš°ì„ )
    â”œâ”€ ìƒˆ ì„ íƒì ìë™ ìƒì„±
    â”œâ”€ ì±„ìš©ê³µê³  ì»¨í…Œì´ë„ˆ íŒ¨í„´ íƒì§€
    â””â”€ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì  ì„ íƒì ì„ íƒ
    â†“
ì±„ìš©ê³µê³  ë°ì´í„° ì¶”ì¶œ
    â”œâ”€ ì„ íƒìë¡œ ìš”ì†Œ ì¶”ì¶œ
    â”œâ”€ í…ìŠ¤íŠ¸ ì •ì œ ë° í•„í„°ë§
    â”œâ”€ ì±„ìš©ê³µê³  ìœ íš¨ì„± ê²€ì¦
    â””â”€ ì™¸êµ­ì¸ ì±„ìš© í‚¤ì›Œë“œ ë§¤ì¹­
    â†“
ê²°ê³¼ ë°˜í™˜
    â”œâ”€ ì„±ê³µ: ì±„ìš©ê³µê³  ëª©ë¡
    â””â”€ ì‹¤íŒ¨: ì˜¤ë¥˜ ì •ë³´ ë° selenium_required ì¡°ì •
```

## ìƒì„¸ ë¡œì§ íë¦„

### 1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë° ì„¤ì • ë¡œë“œ

**JobMonitoringDAG í´ë˜ìŠ¤ ì´ˆê¸°í™”:**
```python
# job_monitoring_logic.py:21-45
def __init__(self, base_dir, worksheet_name, webhook_url_env, results_filename):
    # 1. í™˜ê²½ë³€ìˆ˜ ë° ê¸°ë³¸ ì„¤ì • ë¡œë“œ
    self.base_dir = base_dir  # ì‘ì—… ë””ë ‰í† ë¦¬
    self.worksheet_name = worksheet_name  # ì²˜ë¦¬í•  ì‹œíŠ¸ëª…
    self.webhook_url = os.getenv(webhook_url_env)  # ìŠ¬ë™ ì›¹í›… URL
    self.results_filename = results_filename  # ê²°ê³¼ ì €ì¥ íŒŒì¼ëª…

    # 2. Google Sheets ì—°ë™ ê´€ë¦¬ì ì´ˆê¸°í™”
    self.sheet_manager = GoogleSheetManager()

    # 3. ì„±ëŠ¥ ì„¤ì • ë¡œë“œ
    self.max_workers = int(os.getenv('MAX_WORKERS', 3))  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜

    # 4. ë¡œê±° ì„¤ì • (ì‹œê°„, ë ˆë²¨, ë©”ì‹œì§€ í¬ë§·)
    self.logger = self._setup_logger()
```

**Google Sheets ì—°ë™ ì´ˆê¸°í™”:**
```python
# google_sheet_utils.py:15-30
class GoogleSheetManager:
    def __init__(self):
        # 1. ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ë¡œë“œ
        self.credentials = service_account.Credentials.from_service_account_file(
            'key/credentials.json',
            scopes=['https://www.googleapis.com/auth/spreadsheets']
        )

        # 2. Google Sheets API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        self.service = build('sheets', 'v4', credentials=self.credentials)

        # 3. ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ
        self.spreadsheet_id = os.getenv('GOOGLE_SHEET_KEY')
```

### 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬

**Google Sheetsì—ì„œ íšŒì‚¬ ëª©ë¡ ë¡œë“œ:**
```python
# job_monitoring_logic.py:71-92
def run(self):
    # 1. ì‹œíŠ¸ì—ì„œ íšŒì‚¬ ëª©ë¡ ë°ì´í„° ë¡œë“œ
    df_config = self.sheet_manager.load_sheet_to_df(self.worksheet_name)

    # 2. í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ (íšŒì‚¬_í•œê¸€_ì´ë¦„, job_posting_url)
    required_columns = ['íšŒì‚¬_í•œê¸€_ì´ë¦„', 'job_posting_url']
    if not all(col in df_config.columns for col in required_columns):
        raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {required_columns}")

    # 3. ë¹ˆ URL ì œê±° ë° ë°ì´í„° ì •ì œ
    df_config = df_config.dropna(subset=['job_posting_url'])
    df_config = df_config[df_config['job_posting_url'].str.strip() != '']

    # 4. ì™¸êµ­ì¸ ì±„ìš© í‚¤ì›Œë“œ ì‹œíŠ¸ ë¡œë“œ
    keyword_sheets = ['5000ëŒ€_ê¸°ì—…', '[ë“±ë¡]ì±„ìš©í™ˆí˜ì´ì§€ ëª¨ìŒ']
    if self.worksheet_name in keyword_sheets:
        try:
            foreign_keywords_df = self.sheet_manager.load_sheet_to_df('ì™¸êµ­ì¸_í‚¤ì›Œë“œ')
            self.foreign_keywords = foreign_keywords_df['í‚¤ì›Œë“œ'].dropna().tolist()
        except:
            self.foreign_keywords = []  # í‚¤ì›Œë“œ ì‹œíŠ¸ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸
```

### 3. Selenium í•„ìš”ì„± ìë™ íŒë‹¨

**ë™ì /ì •ì  ì›¹ì‚¬ì´íŠ¸ íŒë‹¨ ë¡œì§:**
```python
# job_monitoring_logic.py:574-620
def _determine_selenium_requirement(self, url, company_name):
    """
    ì›¹ì‚¬ì´íŠ¸ ë¶„ì„ì„ í†µí•œ í¬ë¡¤ë§ ë°©ì‹ ìë™ ê²°ì •
    """
    try:
        # 1. ê¸°ë³¸ HTML í—¤ë” ìš”ì²­ìœ¼ë¡œ ì ‘ê·¼ì„± í™•ì¸
        response = requests.head(url, timeout=10, allow_redirects=True)
        if response.status_code != 200:
            return -1  # ì ‘ê·¼ ë¶ˆê°€

        # 2. HTML ì½˜í…ì¸  ê°€ì ¸ì˜¤ê¸° ì‹œë„
        html_response = requests.get(url, timeout=15, headers=HEADERS)
        if html_response.status_code != 200:
            return -1

        html_content = html_response.text

        # 3. SPA í”„ë ˆì„ì›Œí¬ ê°ì§€
        spa_patterns = [
            r'react',           # React
            r'vue\.js',         # Vue.js
            r'angular',         # Angular
            r'next\.js',        # Next.js
            r'nuxt',            # Nuxt.js
            r'__NEXT_DATA__'    # Next.js íŠ¹ì • íŒ¨í„´
        ]

        for pattern in spa_patterns:
            if re.search(pattern, html_content, re.IGNORECASE):
                self.logger.info(f"{company_name}: SPA í”„ë ˆì„ì›Œí¬ ê°ì§€ - Selenium í•„ìš”")
                return 1

        # 4. JavaScript ì˜ì¡´ë„ ë¶„ì„
        js_indicators = [
            'document.addEventListener',
            'window.onload',
            'ajax',
            'fetch(',
            'XMLHttpRequest'
        ]

        js_count = sum(1 for indicator in js_indicators
                      if indicator in html_content)

        if js_count >= 3:  # ë‹¤ì¤‘ JS íŒ¨í„´ ë°œê²¬ì‹œ
            return 1

        # 5. íŠ¹ì • ë„ë©”ì¸ ì˜ˆì™¸ ì²˜ë¦¬
        domain_exceptions = {
            'workday.com': 1,      # í•­ìƒ ë™ì 
            'lever.co': 1,         # í•­ìƒ ë™ì 
            'greenhouse.io': 1,    # í•­ìƒ ë™ì 
            'notion.site': 1,      # Notion í˜ì´ì§€
        }

        parsed_url = urlparse(url)
        for domain, selenium_required in domain_exceptions.items():
            if domain in parsed_url.netloc:
                return selenium_required

        return 0  # ì •ì  ì‚¬ì´íŠ¸ë¡œ íŒë‹¨

    except Exception as e:
        self.logger.error(f"{company_name} Selenium í•„ìš”ì„± íŒë‹¨ ì‹¤íŒ¨: {e}")
        return -1
```

### 4. HTML ì½˜í…ì¸  ìˆ˜ì§‘

**ë™ì /ì •ì  ë°©ì‹ ìë™ ì„ íƒ:**
```python
# job_monitoring_logic.py:450-520
def get_html_content_for_crawling(self, url, selenium_required):
    """
    ì‚¬ì´íŠ¸ íŠ¹ì„±ì— ë§ëŠ” ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ HTML ìˆ˜ì§‘
    """
    if selenium_required == 1:
        return self._get_html_with_playwright(url)
    else:
        return self._get_html_with_requests(url)

def _get_html_with_requests(self, url):
    """ì •ì  ì‚¬ì´íŠ¸ìš© ê³ ì† HTML ìˆ˜ì§‘"""
    try:
        # 1. ì•ˆì „í•œ í—¤ë” ì„¤ì • (ë´‡ ì°¨ë‹¨ ìš°íšŒ)
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
        }

        # 2. íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ ì„¤ì •
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        return response.text, True

    except Exception as e:
        return None, False

def _get_html_with_playwright(self, url):
    """ë™ì  ì‚¬ì´íŠ¸ìš© ë¸Œë¼ìš°ì € ìë™í™”"""
    try:
        # 1. ë¸Œë¼ìš°ì € ì‹¤í–‰ (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ)
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=True)
            page = browser.new_page()

            # 2. ë¸Œë¼ìš°ì € í™˜ê²½ ì„¤ì •
            page.set_viewport_size({"width": 1920, "height": 1080})
            page.set_extra_http_headers({
                "Accept-Language": "ko-KR,ko;q=0.9,en;q=0.8"
            })

            # 3. í˜ì´ì§€ ë¡œë“œ ë° JS ì‹¤í–‰ ëŒ€ê¸°
            page.goto(url, wait_until='domcontentloaded', timeout=30000)

            # 4. ì¶”ê°€ ë Œë”ë§ ëŒ€ê¸° (AJAX ë¡œë“œ ë“±)
            page.wait_for_timeout(2000)

            # 5. ìµœì¢… HTML ì¶”ì¶œ
            html_content = page.content()
            browser.close()

            return html_content, True

    except Exception as e:
        return None, False
```

### 5. CSS ì„ íƒì ìƒì„± ë° ê²€ì¦

**ê¸°ì¡´ ì„ íƒì ì¬í™œìš© ìš°ì„  ë¡œì§:**
```python
# job_monitoring_logic.py:290-340
def _process_company_complete(self, company_name, url, existing_selector):
    """
    ì„ íƒì ì°¾ê¸°ì™€ í¬ë¡¤ë§ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ” í†µí•© ë¡œì§
    """
    # 1. ê¸°ì¡´ ê²€ì¦ëœ ì„ íƒì ì¬í™œìš© ì²´í¬
    if existing_selector and len(existing_selector.strip()) > 20:
        self.logger.info(f"{company_name}: ê¸°ì¡´ ê²€ì¦ëœ ì„ íƒì ì¬í™œìš©")

        # ê¸°ì¡´ ì„ íƒìë¡œ í¬ë¡¤ë§ ì‹œë„
        html_content, success = self.get_html_content_for_crawling(url, selenium_required)
        if success and html_content:
            job_postings = self._extract_job_postings_from_html(html_content, existing_selector)
            if len(job_postings) > 0:
                # ì„±ê³µì‹œ ê¸°ì¡´ ì„ íƒì ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return {
                    'selector': existing_selector,
                    'selenium_required': selenium_required,
                    'job_postings': job_postings
                }

    # 2. ìƒˆ ì„ íƒì ìƒì„± í•„ìš”
    self.logger.info(f"{company_name}: ìƒˆ ì„ íƒì ìƒì„± ì¤‘...")
    return self._generate_new_selector_and_crawl(company_name, url)
```

**ìƒˆ CSS ì„ íƒì ìë™ ìƒì„±:**
```python
# analyze_titles.py:45-120
class JobPostingSelectorAnalyzer:
    def find_best_job_posting_selector(self, html_content):
        """
        HTMLì—ì„œ ìµœì ì˜ ì±„ìš©ê³µê³  ì„ íƒìë¥¼ ì°¾ëŠ” ë©”ì¸ ë¡œì§
        """
        soup = BeautifulSoup(html_content, 'html.parser')

        # 1. ì±„ìš©ê³µê³  ì „ìš© ì»¨í…Œì´ë„ˆ ìš°ì„  íƒì§€
        job_containers = self._find_job_containers(soup)
        if job_containers:
            return self._analyze_job_container_patterns(job_containers)

        # 2. ì¼ë°˜ì ì¸ ë§í¬ íŒ¨í„´ ë¶„ì„
        all_links = soup.find_all('a', href=True)
        job_links = self._filter_job_related_links(all_links)

        if not job_links:
            return None

        # 3. ì„ íƒì í›„ë³´êµ° ìƒì„± ë° í‰ê°€
        selector_candidates = self._generate_selector_candidates(job_links)
        return self._evaluate_and_select_best(selector_candidates, soup)

    def _find_job_containers(self, soup):
        """ì±„ìš©ê³µê³  ì „ìš© ì»¨í…Œì´ë„ˆ íƒì§€"""
        # ì±„ìš© ê´€ë ¨ í‚¤ì›Œë“œ íŒ¨í„´
        job_keywords = [
            'job', 'career', 'recruit', 'employment', 'position',
            'ì±„ìš©', 'ëª¨ì§‘', 'êµ¬ì¸', 'ì…ì‚¬', 'ì§ë¬´'
        ]

        containers = []

        # classëª…ê³¼ idì—ì„œ ì±„ìš© í‚¤ì›Œë“œ íƒì§€
        for keyword in job_keywords:
            # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì—°ê²°ëœ íŒ¨í„´
            pattern = f'(^|[^a-zA-Z]){keyword}([^a-zA-Z]|$)'

            class_matches = soup.find_all(attrs={'class': re.compile(pattern, re.I)})
            id_matches = soup.find_all(attrs={'id': re.compile(pattern, re.I)})

            containers.extend(class_matches + id_matches)

        return list(set(containers))  # ì¤‘ë³µ ì œê±°

    def _filter_job_related_links(self, links):
        """ì§ë¬´ ê´€ë ¨ ë§í¬ë§Œ í•„í„°ë§"""
        job_related_texts = [
            # í•œê¸€ ì§ë¬´ëª…
            'ê°œë°œì', 'í”„ë¡œê·¸ë˜ë¨¸', 'ì—”ì§€ë‹ˆì–´', 'ë””ìì´ë„ˆ', 'ê¸°íšì',
            'ë§ˆì¼€í„°', 'ì˜ì—…', 'ìš´ì˜', 'ê´€ë¦¬', 'ì „ë¬¸ê°€', 'PM', 'PO',

            # ì˜ë¬¸ ì§ë¬´ëª…
            'developer', 'engineer', 'designer', 'manager', 'analyst',
            'specialist', 'coordinator', 'lead', 'senior', 'junior'
        ]

        filtered_links = []
        for link in links:
            text = link.get_text(strip=True).lower()

            # ì§ë¬´ ê´€ë ¨ í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€ í™•ì¸
            if any(keyword in text for keyword in job_related_texts):
                filtered_links.append(link)

        return filtered_links

    def _generate_selector_candidates(self, job_links):
        """ì„ íƒì í›„ë³´êµ° ìƒì„±"""
        candidates = {}

        for link in job_links:
            # 1. í´ë˜ìŠ¤ ê¸°ë°˜ ì„ íƒì
            if link.get('class'):
                class_selector = 'a.' + '.'.join(link['class'])
                candidates[class_selector] = candidates.get(class_selector, 0) + 1

            # 2. ë¶€ëª¨ ìš”ì†Œ ê¸°ë°˜ ì„ íƒì
            parent = link.parent
            if parent and parent.get('class'):
                parent_selector = f".{'.'.join(parent['class'])} a"
                candidates[parent_selector] = candidates.get(parent_selector, 0) + 1

            # 3. ë³µí•© ì„ íƒì (ë¶€ëª¨+ìì‹)
            if parent and parent.parent:
                grandparent = parent.parent
                if grandparent.get('class'):
                    complex_selector = f".{'.'.join(grandparent['class'])} a"
                    candidates[complex_selector] = candidates.get(complex_selector, 0) + 1

        return candidates

    def _evaluate_and_select_best(self, candidates, soup):
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì  ì„ íƒì ì„ íƒ"""
        scored_candidates = []

        for selector, count in candidates.items():
            try:
                # BeautifulSoup CSS ì„ íƒìë¡œ í…ŒìŠ¤íŠ¸
                matches = soup.select(selector)

                # ì ìˆ˜ ê³„ì‚°
                score = 0

                # 1. ë§¤ì¹­ ê°œìˆ˜ ì ìˆ˜ (ì ë‹¹í•œ ìˆ˜ê°€ ì¢‹ìŒ)
                if 3 <= len(matches) <= 50:
                    score += 30
                elif 1 <= len(matches) <= 2:
                    score += 20
                elif len(matches) > 50:
                    score += 10

                # 2. ì„ íƒì êµ¬ì²´ì„± ì ìˆ˜
                if 'job' in selector.lower():
                    score += 25
                if 'career' in selector.lower():
                    score += 20
                if 'recruit' in selector.lower():
                    score += 20

                # 3. UI ìš”ì†Œ ì œì™¸ (ê°ì )
                ui_elements = ['nav', 'footer', 'header', 'menu', 'sidebar']
                if any(ui_elem in selector.lower() for ui_elem in ui_elements):
                    score -= 30

                # 4. ì„ íƒì ê¸¸ì´ ì ìˆ˜ (ë„ˆë¬´ ë³µì¡í•˜ì§€ ì•Šê²Œ)
                if 10 <= len(selector) <= 50:
                    score += 15

                scored_candidates.append((selector, score, len(matches)))

            except Exception:
                continue  # ì˜ëª»ëœ ì„ íƒìëŠ” ê±´ë„ˆë›°ê¸°

        # ì ìˆ˜ìˆœ ì •ë ¬í•˜ì—¬ ìµœê³  ì ìˆ˜ ë°˜í™˜
        scored_candidates.sort(key=lambda x: x[1], reverse=True)

        return scored_candidates[0][0] if scored_candidates else None
```

### 6. ì±„ìš©ê³µê³  ë°ì´í„° ì¶”ì¶œ ë° ê²€ì¦

**HTMLì—ì„œ ì±„ìš©ê³µê³  ì¶”ì¶œ:**
```python
# job_monitoring_logic.py:520-570
def _extract_job_postings_from_html(self, html_content, selector):
    """
    ì„ íƒìë¥¼ ì‚¬ìš©í•˜ì—¬ HTMLì—ì„œ ì±„ìš©ê³µê³  ì¶”ì¶œ
    """
    try:
        soup = BeautifulSoup(html_content, 'html.parser')

        # 1. CSS ì„ íƒìë¡œ ìš”ì†Œ ì¶”ì¶œ
        elements = soup.select(selector)

        if not elements:
            return []

        job_postings = []
        seen_texts = set()  # ì¤‘ë³µ ì œê±°ìš©

        for element in elements:
            # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ
            text = element.get_text(strip=True)

            # 3. ê¸°ë³¸ í•„í„°ë§
            if not text or len(text) < 2:
                continue

            # 4. ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±°
            filtered_text = self._clean_job_posting_text(text)

            # 5. ì¤‘ë³µ ì œê±°
            if filtered_text and filtered_text not in seen_texts:
                seen_texts.add(filtered_text)

                # 6. ì±„ìš©ê³µê³  ìœ íš¨ì„± ê²€ì¦
                if self._is_valid_job_posting(filtered_text):
                    job_postings.append(filtered_text)

        return job_postings[:50]  # ìµœëŒ€ 50ê°œ ì œí•œ

    except Exception as e:
        self.logger.error(f"ì±„ìš©ê³µê³  ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return []

def _clean_job_posting_text(self, text):
    """ì±„ìš©ê³µê³  í…ìŠ¤íŠ¸ ì •ì œ"""
    # 1. ë‚ ì§œ íŒ¨í„´ ì œê±°
    text = re.sub(r'\d{4}[-./]\d{1,2}[-./]\d{1,2}', '', text)
    text = re.sub(r'\d{1,2}[-./]\d{1,2}[-./]\d{4}', '', text)

    # 2. ì‹œê°„ íŒ¨í„´ ì œê±°
    text = re.sub(r'\d{1,2}:\d{2}', '', text)

    # 3. ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì •ì œ
    text = re.sub(r'[^\w\sê°€-í£()]', ' ', text)
    text = ' '.join(text.split())  # ì—°ì† ê³µë°± ì œê±°

    # 4. ê¸¸ì´ ì œí•œ
    return text[:200] if text else None

def _is_valid_job_posting(self, text):
    """ì±„ìš©ê³µê³  ìœ íš¨ì„± ê²€ì¦"""
    # 1. ìµœì†Œ ê¸¸ì´ ì²´í¬
    if len(text) < 3:
        return False

    # 2. ì§ë¬´ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€
    job_keywords = [
        # í•œê¸€ ì§ë¬´
        'ê°œë°œ', 'í”„ë¡œê·¸ë˜ë¨¸', 'ì—”ì§€ë‹ˆì–´', 'ë””ìì´ë„ˆ', 'ê¸°íš',
        'ë§ˆì¼€íŒ…', 'ì˜ì—…', 'ìš´ì˜', 'ê´€ë¦¬', 'ì „ë¬¸ê°€',

        # ì˜ë¬¸ ì§ë¬´
        'developer', 'engineer', 'designer', 'manager',
        'analyst', 'specialist', 'coordinator'
    ]

    text_lower = text.lower()
    has_job_keyword = any(keyword in text_lower for keyword in job_keywords)

    # 3. ì œì™¸í•  í…ìŠ¤íŠ¸ íŒ¨í„´
    exclude_patterns = [
        'ë¡œê·¸ì¸', 'íšŒì›ê°€ì…', 'í™ˆ', 'ë©”ë‰´', 'ê²€ìƒ‰',
        'login', 'signup', 'home', 'menu', 'search',
        'ì´ì „', 'ë‹¤ìŒ', 'prev', 'next', 'ë”ë³´ê¸°', 'more'
    ]

    has_exclude = any(pattern in text_lower for pattern in exclude_patterns)

    return has_job_keyword and not has_exclude
```

### 7. ì™¸êµ­ì¸ ì±„ìš©ê³µê³  í‚¤ì›Œë“œ ë§¤ì¹­

**í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ ì²˜ë¦¬:**
```python
# job_monitoring_logic.py:780-830
def _highlight_foreign_keywords(self, job_posting):
    """
    ì™¸êµ­ì¸ ì±„ìš©ê³µê³  í‚¤ì›Œë“œë¥¼ í•˜ì´ë¼ì´íŠ¸í•˜ê³  ê°ì§€ ì—¬ë¶€ ë°˜í™˜
    """
    if not self.foreign_keywords:
        return job_posting, False

    highlighted_text = job_posting
    is_foreign = False

    for keyword in self.foreign_keywords:
        keyword = keyword.strip()
        if not keyword:
            continue

        # 1. ëŒ€ì†Œë¬¸ì ë¬´ê´€ ê²€ìƒ‰
        pattern = re.compile(re.escape(keyword), re.IGNORECASE)

        if pattern.search(job_posting):
            is_foreign = True

            # 2. ê¸°ì¡´ ë³¼ë“œì²´ì™€ ì¤‘ë³µ ë°©ì§€
            def replace_func(match):
                matched_text = match.group(0)
                # ì´ë¯¸ *ë¡œ ë‘˜ëŸ¬ì‹¸ì—¬ ìˆëŠ”ì§€ í™•ì¸
                if highlighted_text[max(0, match.start()-1):match.start()] == '*' and \
                   highlighted_text[match.end():match.end()+1] == '*':
                    return matched_text  # ì´ë¯¸ ë³¼ë“œì²´ë©´ ê·¸ëŒ€ë¡œ
                return f'*{matched_text}*'

            # 3. í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ ì ìš©
            highlighted_text = pattern.sub(replace_func, highlighted_text)

    return highlighted_text, is_foreign

def _is_foreign_job_posting(self, job_posting):
    """ì™¸êµ­ì¸ ì±„ìš©ê³µê³  ì—¬ë¶€ë§Œ í™•ì¸ (í•˜ì´ë¼ì´íŠ¸ ì—†ì´)"""
    if not self.foreign_keywords:
        return False

    job_lower = job_posting.lower()
    return any(keyword.strip().lower() in job_lower
              for keyword in self.foreign_keywords if keyword.strip())
```

### 8. ê²°ê³¼ ë¹„êµ ë° ìƒˆ ê³µê³  ê°ì§€

**ì´ì „ ê²°ê³¼ì™€ ë¹„êµ ë¡œì§:**
```python
# job_monitoring_logic.py:690-750
def find_new_jobs(self, current_jobs, existing_jobs):
    """
    í˜„ì¬ í¬ë¡¤ë§ ê²°ê³¼ì™€ ì´ì „ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ìƒˆ ê³µê³  ê°ì§€
    """
    new_jobs = {}

    for company, current_job_list in current_jobs.items():
        if not current_job_list:
            continue

        # 1. ì´ì „ ê²°ê³¼ ë¡œë“œ
        existing_job_list = existing_jobs.get(company, [])

        # 2. ìƒˆ ê³µê³  í•„í„°ë§ (ì§‘í•© ì—°ì‚° ì‚¬ìš©)
        current_set = set(current_job_list)
        existing_set = set(existing_job_list)
        new_job_set = current_set - existing_set

        # 3. ìƒˆ ê³µê³ ê°€ ìˆìœ¼ë©´ ê²°ê³¼ì— ì¶”ê°€
        if new_job_set:
            new_jobs[company] = list(new_job_set)
            self.logger.info(f"{company}: ìƒˆ ê³µê³  {len(new_job_set)}ê°œ ë°œê²¬")

    return new_jobs

def check_suspicious_results(self, current_jobs, existing_jobs, new_jobs):
    """ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë³€ê²½ì‚¬í•­ ê°ì§€"""
    warnings = []

    for company, current_job_list in current_jobs.items():
        existing_job_list = existing_jobs.get(company, [])

        # 1. ê¸°ì¡´ ê³µê³ ê°€ ë§ì•˜ëŠ”ë° ê°‘ìê¸° ì—†ì–´ì§„ ê²½ìš°
        if len(existing_job_list) >= 3 and len(current_job_list) == 0:
            warnings.append(f"{company}: ê¸°ì¡´ {len(existing_job_list)}ê°œ ê³µê³ ê°€ ëª¨ë‘ ì‚¬ë¼ì§")

        # 2. ê³µê³  ìˆ˜ê°€ ê¸‰ê²©íˆ ë³€í•œ ê²½ìš° (50% ì´ìƒ ê°ì†Œ)
        elif len(existing_job_list) > 5:
            decrease_ratio = (len(existing_job_list) - len(current_job_list)) / len(existing_job_list)
            if decrease_ratio > 0.5:
                warnings.append(f"{company}: ê³µê³  ìˆ˜ {decrease_ratio:.0%} ê°ì†Œ ({len(existing_job_list)}â†’{len(current_job_list)})")

    return warnings
```

### 9. Slack ë©”ì‹œì§€ ìƒì„± ë° ì „ì†¡

**êµ¬ì¡°í™”ëœ Block Kit ë©”ì‹œì§€ ìƒì„±:**
```python
# job_monitoring_logic.py:894-951
def send_slack_notification(self, new_jobs, warnings, failed_companies, chunk_info=None):
    """
    Slack Block Kitì„ í™œìš©í•œ êµ¬ì¡°í™”ëœ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡
    """
    if new_jobs:
        total_new_jobs = sum(len(jobs) for jobs in new_jobs.values())
        foreign_job_count = sum(1 for jobs in new_jobs.values()
                               for job in jobs if self._is_foreign_job_posting(job))

        # 1. ë©”ì‹œì§€ í—¤ë” ìƒì„±
        chunk_str = f"({chunk_info}) " if chunk_info else ""
        foreign_info = f" (ì™¸êµ­ì¸ ì±„ìš©: {foreign_job_count}ê°œ ğŸ”®)" if foreign_job_count > 0 else ""
        header_text = f"ğŸ‰ *ìƒˆë¡œìš´ ì±„ìš©ê³µê³  {total_new_jobs}ê°œ ë°œê²¬!*{foreign_info} {chunk_str}({current_time})"

        # 2. ë©”ì‹œì§€ ë¶„í• ì„ ìœ„í•œ ì´ˆê¸°í™”
        current_blocks = []
        current_blocks.append({"type": "section", "text": {"type": "mrkdwn", "text": header_text}})
        current_blocks.append({"type": "divider"})
        current_length = len(header_text) + 50  # ì—¬ìœ ë¶„ í¬í•¨

        # 3. íšŒì‚¬ë³„ ì±„ìš©ê³µê³  ë¸”ë¡ ìƒì„±
        for company, jobs in new_jobs.items():
            # íšŒì‚¬ URL ë§í¬ ì²˜ë¦¬
            company_url = self.company_urls.get(company, "")
            linked_company = f"<{company_url}|{company}>" if company_url else f"*{company}*"
            company_with_time = f"{linked_company} - {formatted_datetime}"

            # ì±„ìš©ê³µê³  ëª©ë¡ ìƒì„±
            job_lines = []
            for job in jobs:
                highlighted_job, is_foreign = self._highlight_foreign_keywords(job)
                job_line = f"â€¢ {highlighted_job}"
                if is_foreign:
                    job_line = f"ğŸ”® {job_line}"
                job_lines.append(job_line)

            job_text = "\n".join(job_lines)
            company_section_text = f"ğŸ“¢ {company_with_time} - {len(jobs)}ê°œ\n{job_text}"

            # 4. ë©”ì‹œì§€ ê¸¸ì´ ì²´í¬ ë° ë¶„í•  ì²˜ë¦¬
            estimated_length = current_length + len(company_section_text) + 100

            if estimated_length > CHAR_LIMIT:  # 2800ì ì´ˆê³¼ì‹œ
                # í˜„ì¬ ë¸”ë¡ë“¤ ë¨¼ì € ì „ì†¡
                payload = {"blocks": current_blocks, "username": "ì±„ìš©ê³µê³  ì•Œë¦¬ë¯¸", "icon_emoji": ":robot_face:"}
                send_payload(payload)

                # ìƒˆ ë¸”ë¡ ì‹œì‘ (ê³„ì† í‘œì‹œ)
                current_blocks = []
                continuation_header = f"ğŸ‰ *ìƒˆë¡œìš´ ì±„ìš©ê³µê³  {total_new_jobs}ê°œ ë°œê²¬!*{foreign_info} {chunk_str}({current_time}) - ê³„ì†"
                current_blocks.append({"type": "section", "text": {"type": "mrkdwn", "text": continuation_header}})
                current_blocks.append({"type": "divider"})
                current_length = len(continuation_header) + 50

            # íšŒì‚¬ ì„¹ì…˜ ì¶”ê°€
            company_section = {"type": "section", "text": {"type": "mrkdwn", "text": company_section_text}}
            current_blocks.append(company_section)
            current_length += len(company_section_text) + 100

        # 5. ë§ˆì§€ë§‰ ë¸”ë¡ë“¤ ì „ì†¡
        if current_blocks:
            payload = {"blocks": current_blocks, "username": "ì±„ìš©ê³µê³  ì•Œë¦¬ë¯¸", "icon_emoji": ":robot_face:"}
            send_payload(payload)
```

### 10. ë°ì´í„° ì €ì¥ ë° ë™ê¸°í™”

**ê²°ê³¼ ì €ì¥ ë° Google Sheets ì—…ë°ì´íŠ¸:**
```python
# job_monitoring_logic.py:750-780
def save_jobs(self, current_jobs):
    """í¬ë¡¤ë§ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    # 1. ì €ì¥í•  ë°ì´í„° êµ¬ì¡° ìƒì„±
    save_data = {}
    for company, jobs in current_jobs.items():
        save_data[company] = jobs if jobs else []

    # 2. JSON í˜•íƒœë¡œ CSVì— ì €ì¥ (í˜¸í™˜ì„±)
    results_path = os.path.join(self.base_dir, 'data', self.results_filename)
    os.makedirs(os.path.dirname(results_path), exist_ok=True)

    # 3. DataFrameìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥
    df_results = pd.DataFrame([
        {'company': company, 'jobs': json.dumps(jobs, ensure_ascii=False)}
        for company, jobs in save_data.items()
    ])

    df_results.to_csv(results_path, index=False, encoding='utf-8-sig')
    self.logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {results_path}")

# Google Sheets ë™ê¸°í™”
# google_sheet_utils.py:80-120
def update_sheet_from_df(self, df, worksheet_name):
    """DataFrameì„ Google Sheetsì— ì•ˆì „í•˜ê²Œ ì—…ë°ì´íŠ¸"""
    try:
        # 1. í—¤ë” ë³´ì¡´ì„ ìœ„í•œ ê¸°ì¡´ ì‹œíŠ¸ êµ¬ì¡° í™•ì¸
        range_name = f'{worksheet_name}!1:1'
        existing_headers = self.service.spreadsheets().values().get(
            spreadsheetId=self.spreadsheet_id,
            range=range_name
        ).execute()

        # 2. ë°ì´í„°ë¥¼ 2ì°¨ì› ë°°ì—´ë¡œ ë³€í™˜
        values = [df.columns.tolist()]  # í—¤ë”
        for _, row in df.iterrows():
            values.append(row.tolist())

        # 3. ì „ì²´ ì‹œíŠ¸ í´ë¦¬ì–´ í›„ ìƒˆ ë°ì´í„° ì…ë ¥
        clear_range = f'{worksheet_name}!A:Z'
        self.service.spreadsheets().values().clear(
            spreadsheetId=self.spreadsheet_id,
            range=clear_range
        ).execute()

        # 4. ìƒˆ ë°ì´í„° ë°°ì¹˜ ì—…ë°ì´íŠ¸
        body = {'values': values}
        self.service.spreadsheets().values().update(
            spreadsheetId=self.spreadsheet_id,
            range=f'{worksheet_name}!A1',
            valueInputOption='RAW',
            body=body
        ).execute()

        self.logger.info(f"Google Sheets ì—…ë°ì´íŠ¸ ì™„ë£Œ: {len(df)}ê°œ í–‰")

    except Exception as e:
        self.logger.error(f"Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
job-monitoring/
â”œâ”€â”€ src/                              # í•µì‹¬ ì†ŒìŠ¤ì½”ë“œ (5ê°œ íŒŒì¼)
â”‚   â”œâ”€â”€ job_monitoring_logic.py       # ë©”ì¸ í¬ë¡¤ë§ ë¡œì§ (979ì¤„)
â”‚   â”œâ”€â”€ job_monitoring_airflow_dag.py # Airflow ìŠ¤ì¼€ì¤„ë§ ì •ì˜
â”‚   â”œâ”€â”€ analyze_titles.py             # ì„ íƒì íŒ¨í„´ ë¶„ì„ê¸° (729ì¤„)
â”‚   â”œâ”€â”€ google_sheet_utils.py         # Google Sheets ì—°ë™
â”‚   â””â”€â”€ utils.py                      # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
â”œâ”€â”€ data/                             # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ job_postings_latest.csv       # ì¼ë°˜ ëª¨ë‹ˆí„°ë§ ê²°ê³¼
â”‚   â””â”€â”€ top_5000_postings_latest.csv  # 5000ëŒ€ ê¸°ì—… ê²°ê³¼
â”œâ”€â”€ logs/                             # Airflow ì‹¤í–‰ ë¡œê·¸
â”‚   â”œâ”€â”€ dag_id=job_monitoring_dag/
â”‚   â”œâ”€â”€ dag_id=top5000_company_monitoring_dag/
â”‚   â””â”€â”€ scheduler/
â”œâ”€â”€ key/                              # ì¸ì¦ íŒŒì¼
â”‚   â””â”€â”€ credentials.json              # Google API ì„œë¹„ìŠ¤ ê³„ì • í‚¤
â”œâ”€â”€ scripts/                          # ë°°í¬ ìë™í™”
â”‚   â”œâ”€â”€ lambda_function.py            # AWS Lambda í•¨ìˆ˜
â”‚   â””â”€â”€ setup-aws-automation.sh       # AWS í™˜ê²½ ì„¤ì •
â”œâ”€â”€ archive_temp/                     # ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸ ë³´ê´€ì†Œ
â”œâ”€â”€ docker-compose.yml                # Docker ì»¨í…Œì´ë„ˆ ì„¤ì •
â”œâ”€â”€ Dockerfile                        # Docker ì´ë¯¸ì§€ ì •ì˜
â”œâ”€â”€ requirements.txt                  # Python ì˜ì¡´ì„±
â””â”€â”€ .env                              # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```

## í•µì‹¬ ê¸°ëŠ¥

### 1. ì§€ëŠ¥í˜• ì›¹ì‚¬ì´íŠ¸ ë¶„ì„

**ë™ì /ì •ì  ì›¹ì‚¬ì´íŠ¸ ìë™ êµ¬ë¶„:**
- SPA(React, Vue, Next.js) í”„ë ˆì„ì›Œí¬ ìë™ ê°ì§€
- JavaScript ì˜ì¡´ë„ ë¶„ì„ìœ¼ë¡œ ë Œë”ë§ ë°©ì‹ ê²°ì •
- requests ì‹¤íŒ¨ ì‹œ Playwrightë¡œ ìë™ ì „í™˜
- ì‚¬ì´íŠ¸ë³„ ë§ì¶¤ ìµœì í™” ë¡œì§

**CSS ì„ íƒì ìë™ ìƒì„±:**
- ê¸°ì¡´ ê²€ì¦ëœ ì„ íƒì ì¬í™œìš© ìš°ì„  (20ì ì´ìƒ)
- ì±„ìš©ê³µê³  ì»¨í…Œì´ë„ˆ íŒ¨í„´ ì¸ì‹ (job, recruit, career)
- ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìµœì  ì„ íƒì ì„ íƒ
- UI ìš”ì†Œ ì œì™¸ í•„í„° (ë„¤ë¹„ê²Œì´ì…˜, í‘¸í„°, ê´‘ê³ )

### 2. ê³ ì„±ëŠ¥ ë³‘ë ¬ ì²˜ë¦¬

**ë©€í‹°ìŠ¤ë ˆë“œ í¬ë¡¤ë§:**
- ThreadPoolExecutor ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬ (ê¸°ë³¸ 3ê°œ ì›Œì»¤)
- Selenium í•„ìš”ì„± íŒë‹¨ê³¼ í¬ë¡¤ë§ ë™ì‹œ ë³‘ë ¬í™”
- ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± í™•ë³´

**ì•ˆì „í•œ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬:**
- 5000ëŒ€ ê¸°ì—…ì„ 100ê°œì”© ì²­í¬ ë¶„í• 
- ì²­í¬ ê°„ 2ë¶„ ëŒ€ê¸°ë¡œ ì„œë²„ ë¶€í•˜ ë°©ì§€
- ì¤‘ê°„ ì‹¤íŒ¨ ì‹œì—ë„ ì²˜ë¦¬ ê³„ì† ë° ë³µêµ¬

### 3. ìŠ¤ë§ˆíŠ¸ ì•Œë¦¼ ì‹œìŠ¤í…œ

**ì™¸êµ­ì¸ ì±„ìš©ê³µê³  í•„í„°ë§:**
- Google Sheets ê¸°ë°˜ í‚¤ì›Œë“œ ê´€ë¦¬
- ì‹¤ì‹œê°„ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ (`*í‚¤ì›Œë“œ*`)
- ê¸°ì¡´ ë³¼ë“œì²´ì™€ì˜ ì¤‘ë³µ ë°©ì§€ ë¡œì§
- ì´ëª¨ì§€ë¡œ ì‹œê°ì  êµ¬ë¶„

**êµ¬ì¡°í™”ëœ Slack ë©”ì‹œì§€:**
- Block Kit ê¸°ë°˜ ê°€ë…ì„± ë†’ì€ ë©”ì‹œì§€
- íšŒì‚¬ëª… í´ë¦­ ì‹œ ì±„ìš© í˜ì´ì§€ ì´ë™
- í•œêµ­ ì‹œê°„ ê¸°ì¤€ ìƒì„¸ ì‹œê°„ ì •ë³´
- ì‹¤íŒ¨ ì›ì¸ê³¼ í•´ê²° ë°©ë²• ì•ˆë‚´

### 4. ë°ì´í„° ê´€ë¦¬ ë° ëª¨ë‹ˆí„°ë§

**Google Sheets ì¤‘ì•™ ê´€ë¦¬:**
- ì›¹ ê¸°ë°˜ íšŒì‚¬ ì •ë³´ ê´€ë¦¬
- ì‹¤ì‹œê°„ ì„¤ì • ë³€ê²½ ë°˜ì˜
- í—¤ë” ë³´ì¡´ ì•ˆì „í•œ ì—…ë°ì´íŠ¸
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬

**ê²°ê³¼ ì¶”ì  ë° ë¶„ì„:**
- ì´ì „ ê²°ê³¼ì™€ ìë™ ë¹„êµ
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ë³€ê²½ì‚¬í•­ ê°ì§€ (ê¸°ì¡´ ê³µê³  ëª¨ë‘ ì‚¬ë¼ì§„ ê²½ìš°)
- CSV ê¸°ë°˜ ì´ë ¥ ê´€ë¦¬
- ì„±ê³¼ ë¡œê·¸ ìë™ ê¸°ë¡

## ì„¤ì¹˜ ë° ì„¤ì •

### 1. ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­
```bash
# Python 3.8+ í•„ìˆ˜
python --version  # 3.8 ì´ìƒ í™•ì¸

# Docker & Docker Compose
docker --version
docker-compose --version
```

### 2. í”„ë¡œì íŠ¸ ì„¤ì •
```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-repo/kowork-scaper.git
cd kowork-scaper

# 2. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
cp .env.example .env
# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ ì‹¤ì œ ê°’ ì…ë ¥
```

### 3. í™˜ê²½ë³€ìˆ˜ ì„¤ì • (.env)
```env
# Airflow ì„¤ì •
AIRFLOW_UID=50000

# Google Sheets API
GOOGLE_SHEET_KEY=your_sheet_key_here

# Slack Webhook URLs
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR_WEBHOOK
TOP5000COMPANY_URL=https://hooks.slack.com/services/YOUR_TOP5000_WEBHOOK

# ì„±ëŠ¥ ì„¤ì •
MAX_WORKERS=3  # ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
```

### 4. Google API ì„¤ì •
1. [Google Cloud Console](https://console.cloud.google.com/)ì—ì„œ ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±
2. Google Sheets API í™œì„±í™”
3. ì„œë¹„ìŠ¤ ê³„ì • ìƒì„± ë° JSON í‚¤ ë‹¤ìš´ë¡œë“œ
4. í‚¤ íŒŒì¼ì„ `key/credentials.json`ì— ì €ì¥
5. ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì„ Google Sheetsì— í¸ì§‘ìë¡œ ì¶”ê°€

### 5. Docker ì‹¤í–‰
```bash
# ì»¨í…Œì´ë„ˆ ë¹Œë“œ ë° ì‹¤í–‰
docker-compose up -d

# ì‹¤í–‰ ìƒíƒœ í™•ì¸
docker-compose ps

# ì›¹ UI ì ‘ì†: http://localhost:8080
# ê¸°ë³¸ ê³„ì •: admin / admin
```

## ìš´ì˜ ê°€ì´ë“œ

### ì¼ìƒ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

**ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸:**
```bash
# ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker-compose ps

# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
docker-compose logs -f webserver scheduler

# ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰
du -sh data/ logs/
```

**DAG ê´€ë¦¬ (Airflow Web UI):**
- DAG ì‹¤í–‰ ìƒíƒœ: Success/Failed/Running í™•ì¸
- ì‹¤í–‰ ì‹œê°„ ëª¨ë‹ˆí„°ë§: ì¼ë°˜ 30ë¶„, 5000ëŒ€ ê¸°ì—… 2ì‹œê°„ ì´ë‚´
- ìˆ˜ë™ ì‹¤í–‰ ì‹œ: `Trigger DAG` ë²„íŠ¼ ì‚¬ìš©

### Google Sheets ì„¤ì • ê´€ë¦¬

**ì‹œíŠ¸ êµ¬ì¡°:**
| ì»¬ëŸ¼ëª… | ì„¤ëª… | ì˜ˆì‹œ |
|--------|------|------|
| `íšŒì‚¬_í•œê¸€_ì´ë¦„` | íšŒì‚¬ëª… | `ì‚¼ì„±ì „ì` |
| `job_posting_url` | ì±„ìš© í˜ì´ì§€ URL | `https://company.com/careers` |
| `selector` | CSS ì„ íƒì (ìë™ìƒì„±) | `div.job-list a.job-title` |
| `selenium_required` | í¬ë¡¤ë§ ë°©ì‹ | `0`: requests, `1`: Selenium, `-1`: ì‹¤íŒ¨ |

**ìƒˆ íšŒì‚¬ ì¶”ê°€ ë°©ë²•:**
1. Google Sheetsì—ì„œ ìƒˆ í–‰ ì¶”ê°€
2. `íšŒì‚¬_í•œê¸€_ì´ë¦„`ê³¼ `job_posting_url`ë§Œ ì…ë ¥
3. `selector`ì™€ `selenium_required`ëŠ” ë¹ˆ ê°’ìœ¼ë¡œ ë‘ê¸° (ìë™ ìƒì„±)
4. ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ê°’ ì„¤ì •ë¨

### ë¬¸ì œ ìƒí™©ë³„ ëŒ€ì‘

**`selenium_required` ê°’ ì˜ë¯¸:**
- `0`: requests ë°©ì‹ìœ¼ë¡œ ì •ìƒ í¬ë¡¤ë§ ê°€ëŠ¥
- `1`: Selenium ë¸Œë¼ìš°ì € ìë™í™” í•„ìš” (SPA ì‚¬ì´íŠ¸)
- `-1`: HTML ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (ì ‘ê·¼ ì°¨ë‹¨, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜)
- `-2`: ì„ íƒì ìƒì„± ì‹¤íŒ¨ (ì±„ìš©ê³µê³  ì˜ì—­ ì°¾ì„ ìˆ˜ ì—†ìŒ)

**ë¬¸ì œ í•´ê²° ë‹¨ê³„:**
1. **`-1` ì˜¤ë¥˜**: URL ìœ íš¨ì„± í™•ì¸, ì‚¬ì´íŠ¸ ì ‘ê·¼ì„± ì²´í¬
2. **`-2` ì˜¤ë¥˜**: ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ í™•ì¸, ìˆ˜ë™ ì„ íƒì ì…ë ¥ ê³ ë ¤
3. **ì¤‘ë³µ/ëˆ„ë½**: í•´ë‹¹ íšŒì‚¬ `selector` ê°’ ì‚­ì œí•˜ì—¬ ì¬ìƒì„± ìœ ë„

## ê¸°ìˆ  ë¬¸ì„œ

### í•µì‹¬ í´ë˜ìŠ¤ ìƒì„¸ ì„¤ëª…

#### JobMonitoringDAG í´ë˜ìŠ¤
**ì—­í• **: ì „ì²´ ëª¨ë‹ˆí„°ë§ í”„ë¡œì„¸ìŠ¤ ê´€ë¦¬ ë° ì¡°ìœ¨

**ì£¼ìš” ë©”ì„œë“œ:**
- `run()`: ë©”ì¸ ì‹¤í–‰ ë¡œì§, DAGë³„ ì²˜ë¦¬ ë°©ì‹ ë¶„ê¸°
- `process_companies_integrated()`: ì „ì²˜ë¦¬ì™€ í¬ë¡¤ë§ì„ í†µí•©í•œ ê³ íš¨ìœ¨ ì²˜ë¦¬
- `_process_company_complete()`: ê°œë³„ íšŒì‚¬ì˜ ì„ íƒì ì°¾ê¸°ì™€ í¬ë¡¤ë§ì„ ë™ì‹œ ì²˜ë¦¬
- `get_html_content_for_crawling()`: Playwright/requests ë°©ì‹ì„ ìë™ ì„ íƒí•˜ì—¬ HTML ìˆ˜ì§‘
- `send_slack_notification()`: ì™¸êµ­ì¸ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ í¬í•¨ êµ¬ì¡°í™”ëœ ì•Œë¦¼ ë°œì†¡

#### JobPostingSelectorAnalyzer í´ë˜ìŠ¤
**ì—­í• **: ì±„ìš©ê³µê³  ì˜ì—­ ìë™ íƒì§€ ë° CSS ì„ íƒì ìƒì„±

**íŒ¨í„´ ë¶„ì„ ì•Œê³ ë¦¬ì¦˜:**
1. ì±„ìš©ê³µê³  ì „ìš© ì»¨í…Œì´ë„ˆ ìš°ì„  íƒì§€ (job, recruit, career í‚¤ì›Œë“œ)
2. ì§ë¬´ ê´€ë ¨ í…ìŠ¤íŠ¸ í•„í„°ë§ (ê°œë°œì, ì—”ì§€ë‹ˆì–´, ë””ìì´ë„ˆ ë“±)
3. UI ìš”ì†Œ ì œì™¸ (ë„¤ë¹„ê²Œì´ì…˜, í‘¸í„°, ë‚ ì§œ ë“±)
4. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒì í’ˆì§ˆ í‰ê°€

#### GoogleSheetManager í´ë˜ìŠ¤
**ì—­í• **: Google Sheetsì™€ì˜ ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”

**ë™ê¸°í™” ì „ëµ:**
- ì„œë¹„ìŠ¤ ê³„ì • ê¸°ë°˜ ì•ˆì „í•œ ì¸ì¦
- í—¤ë” ë³´ì¡´í•˜ë©´ì„œ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸
- ëŒ€ìš©ëŸ‰ ë°ì´í„° ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

### ì„±ëŠ¥ ìµœì í™” ì„¤ì •

**ë³‘ë ¬ ì²˜ë¦¬ ì¡°ì •:**
```python
# .env íŒŒì¼
MAX_WORKERS=3  # CPU ì½”ì–´ ìˆ˜ì— ë§ì¶° ì¡°ì • (ê¶Œì¥: 2-4)
```

**ì²­í¬ í¬ê¸° ì¡°ì •:**
```python
# src/job_monitoring_logic.py 106ë¼ì¸
chunk_size = 100  # ë©”ëª¨ë¦¬ì™€ ì•ˆì •ì„± ê³ ë ¤í•˜ì—¬ 50-150 ë²”ìœ„ì—ì„œ ì¡°ì •
```

**ëŒ€ê¸° ì‹œê°„ ì¡°ì •:**
```python
# src/job_monitoring_logic.py 145ë¼ì¸
time.sleep(120)  # ì„œë²„ ë¶€í•˜ì— ë”°ë¼ 60-300ì´ˆ ë²”ìœ„ì—ì„œ ì¡°ì •
```

## ë¬¸ì œí•´ê²°

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œ

#### Docker ê´€ë ¨ ë¬¸ì œ
```bash
# ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker-compose down
docker-compose up -d --build

# í¬íŠ¸ ì¶©ëŒ í•´ê²°
lsof -i :8080  # ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ í™•ì¸
```

#### í¬ë¡¤ë§ ê´€ë ¨ ë¬¸ì œ
- **ì ‘ê·¼ ì°¨ë‹¨**: User-Agent ë³€ê²½, ìš”ì²­ ê°„ê²© ì¦ê°€
- **ì„ íƒì ì‹¤íŒ¨**: ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½ í™•ì¸, Google Sheetsì—ì„œ selector ê°’ ì‚­ì œ
- **ì„±ëŠ¥ ì €í•˜**: MAX_WORKERS ê°ì†Œ, chunk_size ì¡°ì •

#### Google Sheets ì—°ë™ ë¬¸ì œ
```bash
# ì¸ì¦ ì˜¤ë¥˜
ls -la key/credentials.json  # íŒŒì¼ ì¡´ì¬ í™•ì¸
# Google Cloud Consoleì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ í™•ì¸

# API í• ë‹¹ëŸ‰ ì´ˆê³¼
# Google Cloud Console -> APIs & Services -> Quotasì—ì„œ í™•ì¸
```

---

**ì‹œìŠ¤í…œ ë²„ì „**: v2.5.0
**ë¬¸ì„œ ì—…ë°ì´íŠ¸**: 2024ë…„ 9ì›” 25ì¼
**ìœ ì§€ë³´ìˆ˜**: ë¦¬íŒ©í† ë§ ì™„ë£Œ, í•µì‹¬ ê¸°ëŠ¥ë§Œ ìœ ì§€
