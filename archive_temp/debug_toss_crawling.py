#!/usr/bin/env python3
"""í† ìŠ¤ ì±„ìš©ê³µê³  ìˆ˜ì§‘ ë¬¸ì œ ë””ë²„ê·¸"""

import sys
sys.path.append('src')

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
import time

def debug_toss_crawling():
    print("ğŸ” í† ìŠ¤ ì±„ìš©ê³µê³  ìˆ˜ì§‘ ë””ë²„ê·¸")
    
    url = "https://toss.im/career/jobs"
    selector = "a.css-g65o95 div.css-16fusbk"
    
    print(f"URL: {url}")
    print(f"ì…€ë ‰í„°: {selector}")
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    
    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        
        print(f"\n=== Seleniumìœ¼ë¡œ í˜ì´ì§€ ë¡œë”© ===")
        driver.get(url)
        time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        
        # í˜„ì¬ URL í™•ì¸
        current_url = driver.current_url
        print(f"í˜„ì¬ URL: {current_url}")
        
        # HTML ê°€ì ¸ì˜¤ê¸°
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        print(f"HTML í¬ê¸°: {len(html_content)} bytes")
        
        # ì§€ì •ëœ ì…€ë ‰í„°ë¡œ ì±„ìš©ê³µê³  ì°¾ê¸°
        job_postings = soup.select(selector)
        print(f"\n=== ì§€ì •ëœ ì…€ë ‰í„° ê²°ê³¼ ===")
        print(f"'{selector}': {len(job_postings)}ê°œ ë°œê²¬")
        
        for i, posting in enumerate(job_postings[:10], 1):
            text = posting.get_text(strip=True)
            print(f"  {i:2d}. {text}")
        
        # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ì…€ë ‰í„°ë“¤ ì‹œë„
        print(f"\n=== ë‹¤ë¥¸ ì…€ë ‰í„°ë“¤ ì‹œë„ ===")
        alternative_selectors = [
            "a.css-g65o95",
            "div.css-16fusbk", 
            "[class*='css-g65o95']",
            "[class*='css-16fusbk']",
            "a[href*='/career/jobs/']",
            ".job-item", ".position", ".career-item",
            "h3", "h4", ".title"
        ]
        
        for alt_selector in alternative_selectors:
            try:
                elements = soup.select(alt_selector)
                if elements:
                    print(f"{alt_selector:30s}: {len(elements):3d}ê°œ")
                    # ì±„ìš©ê³µê³  ê°™ì€ í…ìŠ¤íŠ¸ë“¤ í™•ì¸
                    job_like = []
                    for elem in elements[:5]:
                        text = elem.get_text(strip=True)
                        if len(text) > 5 and len(text) < 100:
                            job_like.append(text)
                    
                    if job_like:
                        for i, text in enumerate(job_like, 1):
                            print(f"    {i}. {text}")
            except Exception as e:
                print(f"{alt_selector:30s}: ì˜¤ë¥˜ - {e}")
        
        # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì±„ìš©ê³µê³  ìˆ˜ ì¶”ì •
        print(f"\n=== ì „ì²´ ì±„ìš©ê³µê³  ìˆ˜ ì¶”ì • ===")
        all_text = soup.get_text()
        
        # "ê°œë°œì", "ì—”ì§€ë‹ˆì–´", "ë””ìì´ë„ˆ" ë“±ì´ í¬í•¨ëœ ë¼ì¸ ìˆ˜
        lines = all_text.split('\n')
        job_keywords = ['ê°œë°œì', 'ì—”ì§€ë‹ˆì–´', 'ë””ìì´ë„ˆ', 'ë§¤ë‹ˆì €', 'PM', 'ë§ˆì¼€íŒ…', 'ì˜ì—…', 'QA']
        
        job_lines = []
        for line in lines:
            line = line.strip()
            if len(line) > 5 and len(line) < 50:  # ì ì ˆí•œ ê¸¸ì´
                if any(keyword in line for keyword in job_keywords):
                    job_lines.append(line)
        
        print(f"ì±„ìš©ê³µê³ ë¡œ ë³´ì´ëŠ” ë¼ì¸ë“¤: {len(job_lines)}ê°œ")
        for i, line in enumerate(job_lines[:15], 1):
            print(f"  {i:2d}. {line}")
        
        if len(job_lines) > len(job_postings):
            print(f"\nâš ï¸  ì‹¤ì œ ì±„ìš©ê³µê³ ({len(job_lines)}ê°œ) > ìˆ˜ì§‘ëœ ê³µê³ ({len(job_postings)}ê°œ)")
            print("ì…€ë ‰í„°ê°€ ëª¨ë“  ì±„ìš©ê³µê³ ë¥¼ í¬ì°©í•˜ì§€ ëª»í•˜ê³  ìˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
    finally:
        if driver:
            driver.quit()

if __name__ == "__main__":
    debug_toss_crawling()