#!/usr/bin/env python3
"""ê°œì„ ëœ ë¡œì§ìœ¼ë¡œ ì‚¼ì„±SDS ì…€ë ‰í„° í…ŒìŠ¤íŠ¸"""

import sys
import os
sys.path.append('src')

import requests
from bs4 import BeautifulSoup
from analyze_titles import JobPostingSelectorAnalyzer

def test_samsung_selector():
    print("ğŸ” ê°œì„ ëœ ë¡œì§ìœ¼ë¡œ ì‚¼ì„±SDS ì…€ë ‰í„° ë¶„ì„...")
    
    url = "https://www.samsungsds.com/kr/careers/overview/about_care_over.html"
    
    try:
        # HTML ê°€ì ¸ì˜¤ê¸°
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print(f"âœ… HTML ê°€ì ¸ì˜¤ê¸° ì„±ê³µ ({len(response.content)} bytes)")
        
        # ê°œì„ ëœ ë¶„ì„ê¸°ë¡œ í…ŒìŠ¤íŠ¸
        analyzer = JobPostingSelectorAnalyzer()
        
        print("\n=== ê°œì„ ëœ í‚¤ì›Œë“œë¡œ potential job posting ì²´í¬ ===")
        test_texts = ["ì‚¬ì—… ê°œë°œ", "R&D", "ê°œë°œì", "ì—”ì§€ë‹ˆì–´", "ë””ìì´ë„ˆ"]
        for text in test_texts:
            result = analyzer._is_potential_job_posting(text)
            print(f"'{text}': {result}")
        
        # ì‹¤ì œ ì…€ë ‰í„° ë¶„ì„
        print(f"\n=== ìë™ ì…€ë ‰í„° ë¶„ì„ ===")
        best_selector, titles = analyzer.find_best_selector(soup)
        
        if best_selector:
            print(f"ğŸ¯ ì°¾ì€ ìµœì  ì…€ë ‰í„°: {best_selector}")
            print(f"ğŸ“‹ ì±„ìš©ê³µê³  ëª©ë¡ ({len(titles)}ê°œ):")
            for i, title in enumerate(titles[:10], 1):
                print(f"  {i}. {title}")
        else:
            print("âŒ ì ì ˆí•œ ì…€ë ‰í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # ìˆ˜ë™ìœ¼ë¡œ ì˜¬ë°”ë¥¸ ì…€ë ‰í„° í…ŒìŠ¤íŠ¸
        print(f"\n=== ì˜¬ë°”ë¥¸ ì…€ë ‰í„° ìˆ˜ë™ í…ŒìŠ¤íŠ¸ ===")
        correct_selectors = [
            "ul.abt_care_list2 li .tit",
            "ul.abt_care_list2 li strong.tit",
            ".abt_care_list2 li .tit"
        ]
        
        for selector in correct_selectors:
            try:
                elements = soup.select(selector)
                titles = [elem.get_text(strip=True) for elem in elements]
                print(f"{selector:30s}: {len(titles)}ê°œ")
                for i, title in enumerate(titles, 1):
                    print(f"  {i}. {title}")
            except Exception as e:
                print(f"{selector:30s}: ì˜¤ë¥˜ - {e}")
        
        # ëª¨ë“  potential elements í™•ì¸
        print(f"\n=== ëª¨ë“  potential elements í™•ì¸ ===")
        count = 0
        for element in soup.find_all(['p', 'div', 'span', 'a', 'strong', 'h2', 'h3', 'h4', 'li', 'dt', 'td']):
            text = element.get_text(strip=True)
            if analyzer._is_potential_job_posting(text):
                count += 1
                if count <= 10:
                    parent_info = f"{element.name}"
                    if element.get('class'):
                        parent_info += f".{'.'.join(element.get('class'))}"
                    print(f"  {count}. [{parent_info}] {text}")
        
        print(f"ì´ potential elements: {count}ê°œ")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")

if __name__ == "__main__":
    test_samsung_selector()