#!/usr/bin/env python3
"""ì„ íƒì ë¶„ì„ ì‹¤íŒ¨í•œ íšŒì‚¬ë“¤ ë””ë²„ê·¸"""

import sys
import os
sys.path.append('src')

import requests
from bs4 import BeautifulSoup
from analyze_titles import JobPostingSelectorAnalyzer

def analyze_failed_company(company_name, url):
    print(f"\n{'='*60}")
    print(f"ğŸ” {company_name} ë¶„ì„")
    print(f"URL: {url}")
    print(f"{'='*60}")
    
    try:
        # HTML ê°€ì ¸ì˜¤ê¸°
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        
        print(f"âœ… HTML ê°€ì ¸ì˜¤ê¸° ì„±ê³µ ({len(response.content)} bytes)")
        
        # ë¶„ì„ê¸° ì´ˆê¸°í™”
        analyzer = JobPostingSelectorAnalyzer()
        
        # 1. potential elements í™•ì¸
        print(f"\n=== 1. Potential Elements ê²€ì‚¬ ===")
        potential_count = 0
        potential_elements = []
        
        for element in soup.find_all(['p', 'div', 'span', 'a', 'strong', 'h2', 'h3', 'h4', 'li', 'dt', 'td']):
            # blacklist ì²´í¬
            is_blacklisted = any(
                parent.name in analyzer.blacklist or 
                any(b in (parent.get('class', []) + ([parent.get('id')] if parent.get('id') else [])) 
                    for b in analyzer.blacklist) 
                for parent in element.find_parents()
            )
            
            if is_blacklisted:
                continue
                
            text = element.get_text(strip=True)
            if analyzer._is_potential_job_posting(text):
                potential_count += 1
                potential_elements.append((element, text))
                if potential_count <= 15:
                    parent_info = f"{element.name}"
                    if element.get('class'):
                        parent_info += f".{'.'.join(element.get('class'))}"
                    print(f"  {potential_count:2d}. [{parent_info:30s}] {text[:80]}")
        
        print(f"\nì´ potential elements: {potential_count}ê°œ")
        
        if potential_count < 3:
            print(f"âŒ Potential elementsê°€ {potential_count}ê°œë¡œ ë¶€ì¡±í•¨ (ìµœì†Œ 3ê°œ í•„ìš”)")
            
            # í‚¤ì›Œë“œë³„ ì„¸ë¶€ ë¶„ì„
            print(f"\n=== í‚¤ì›Œë“œë³„ ì„¸ë¶€ ë¶„ì„ ===")
            job_keywords = analyzer.job_keywords
            for keyword in job_keywords[:10]:  # ì²˜ìŒ 10ê°œë§Œ
                elements = soup.find_all(string=lambda text: text and keyword in text)
                if elements:
                    print(f"'{keyword}': {len(elements)}ê°œ ë°œê²¬")
                    for elem in elements[:2]:
                        text = elem.strip()
                        if len(text) > 5:
                            parent = elem.parent
                            if parent:
                                tag_info = f"{parent.name}"
                                if parent.get('class'):
                                    tag_info += f".{'.'.join(parent.get('class'))}"
                                is_potential = analyzer._is_potential_job_posting(text)
                                print(f"  - [{tag_info:20s}] {text[:60]} â†’ {is_potential}")
            
            return None, []
        
        # 2. ì…€ë ‰í„° ë¶„ì„ ì‹œë„
        print(f"\n=== 2. ì…€ë ‰í„° ë¶„ì„ ì‹œë„ ===")
        best_selector, titles = analyzer.find_best_selector(soup)
        
        if best_selector:
            print(f"ğŸ¯ ì°¾ì€ ìµœì  ì…€ë ‰í„°: {best_selector}")
            print(f"ğŸ“‹ ì±„ìš©ê³µê³  ëª©ë¡ ({len(titles)}ê°œ):")
            for i, title in enumerate(titles[:10], 1):
                print(f"  {i:2d}. {title}")
        else:
            print("âŒ ì ì ˆí•œ ì…€ë ‰í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        # 3. ìˆ˜ë™ íŒ¨í„´ ê²€ì‚¬
        print(f"\n=== 3. ìˆ˜ë™ íŒ¨í„´ ê²€ì‚¬ ===")
        common_job_selectors = [
            'ul li', 'ol li', '.list li', '.job-list li', '.career-list li',
            '.job-item', '.position', '.recruit', '.career', '.opening',
            'h3', 'h4', '.title', '.job-title', '.position-title',
            'a[href*="job"]', 'a[href*="career"]', 'a[href*="position"]'
        ]
        
        for selector in common_job_selectors:
            try:
                elements = soup.select(selector)
                if elements:
                    job_like_count = 0
                    titles = []
                    for elem in elements:
                        text = elem.get_text(strip=True)
                        if text and len(text) > 2:
                            titles.append(text)
                            if analyzer._is_potential_job_posting(text):
                                job_like_count += 1
                    
                    if job_like_count >= 3 or len(titles) >= 5:
                        print(f"ğŸ” {selector:25s}: {len(elements):3d}ê°œ, ì±„ìš©ê´€ë ¨ {job_like_count}ê°œ")
                        for i, title in enumerate(titles[:5], 1):
                            is_potential = analyzer._is_potential_job_posting(title)
                            print(f"    {i}. {title[:60]} â†’ {is_potential}")
                        if job_like_count >= 3:
                            print(f"    âœ… ìœ ë ¥í•œ ì…€ë ‰í„°!")
                    elif len(titles) > 0:
                        print(f"   {selector:25s}: {len(elements):3d}ê°œ, ì±„ìš©ê´€ë ¨ {job_like_count}ê°œ")
            except Exception as e:
                pass
        
        return best_selector, titles
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return None, []

def main():
    # ì‹¤íŒ¨í•œ íšŒì‚¬ë“¤
    failed_companies = [
        ("ë§ˆì´ë‹¤ìŠ¤ì•„ì´í‹°", "https://midas.recruiter.co.kr/career/home"),
        ("ë”íŒŒìš´ë”ì¦ˆ", "https://thevcfounders.com/career"),  # ì˜ˆìƒ URL
        ("ë„¤ì˜¤íŒœ", "https://www.neopharm.co.kr/career"),  # ì˜ˆìƒ URL
        ("ìŠ¤í† ë¦¬íƒ€ì½”", "https://career.storytaco.com/"),  # ì˜ˆìƒ URL
        ("ì•„ì´ë¦¬ìŠ¤ë¸Œë¼ì´íŠ¸", "https://www.irisbright.com/career"),  # ì˜ˆìƒ URL
        ("ì•„ì´ì— ë±…í¬", "https://www.i-m.co.kr/career")  # ì˜ˆìƒ URL
    ]
    
    # ìš°ì„  ë§ˆì´ë‹¤ìŠ¤ì•„ì´í‹°ë§Œ ë¶„ì„
    company, url = failed_companies[0]
    analyze_failed_company(company, url)

if __name__ == "__main__":
    main()