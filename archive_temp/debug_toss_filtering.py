#!/usr/bin/env python3
"""í† ìŠ¤ í•„í„°ë§ ë¬¸ì œ ìƒì„¸ ë””ë²„ê·¸"""

import sys
sys.path.append('src')

from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from analyze_titles import JobPostingSelectorAnalyzer
import time

def debug_toss_filtering():
    print("ğŸ” í† ìŠ¤ í•„í„°ë§ ë¬¸ì œ ìƒì„¸ ë””ë²„ê·¸")
    
    url = "https://toss.im/career/jobs"
    selector = "a.css-g65o95 div.css-16fusbk"
    
    # Chrome ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    
    driver = None
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.get(url)
        time.sleep(3)
        
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # ì±„ìš©ê³µê³  ìš”ì†Œë“¤ ê°€ì ¸ì˜¤ê¸°
        postings = soup.select(selector)
        print(f"ì „ì²´ í¬ìŠ¤íŒ…: {len(postings)}ê°œ")
        
        # í•„í„° ë¶„ì„ê¸°
        analyzer = JobPostingSelectorAnalyzer()
        
        # í•„í„°ë§ ì „í›„ ë¹„êµ
        all_texts = [post.get_text(strip=True) for post in postings]
        filtered_texts = [text for text in all_texts if analyzer._is_potential_job_posting(text)]
        
        print(f"í•„í„°ë§ í›„: {len(filtered_texts)}ê°œ")
        print(f"ì œê±°ë¨: {len(all_texts) - len(filtered_texts)}ê°œ")
        
        # ì œê±°ëœ í•­ëª©ë“¤ ë¶„ì„
        removed_texts = [text for text in all_texts if not analyzer._is_potential_job_posting(text)]
        
        print(f"\n=== ì œê±°ëœ í•­ëª©ë“¤ (ì²˜ìŒ 20ê°œ) ===")
        for i, text in enumerate(removed_texts[:20], 1):
            print(f"{i:2d}. {text[:100]}")
            
            # ì™œ ì œê±°ë˜ì—ˆëŠ”ì§€ ë¶„ì„
            reasons = []
            if len(text) < 3 or len(text) > 150:
                reasons.append(f"ê¸¸ì´ ë¬¸ì œ ({len(text)}ì)")
                
            # ì œì™¸ íŒ¨í„´ ì²´í¬
            for pattern in analyzer.exclude_patterns:
                import re
                if re.search(pattern, text, re.IGNORECASE):
                    reasons.append(f"ì œì™¸ íŒ¨í„´: {pattern}")
                    break
            
            # í‚¤ì›Œë“œ ì²´í¬
            has_job_keyword = any(keyword in text for keyword in analyzer.job_keywords)
            job_title_pattern = r'(ë°±ì—”ë“œ|í”„ë¡ íŠ¸ì—”ë“œ|í’€ìŠ¤íƒ|ëª¨ë°”ì¼|ì›¹|UI/UX|ê·¸ë˜í”½|ë¸Œëœë“œ|ë§ˆì¼€íŒ…|ë°ì´í„°|AI|ML|DevOps|QA|ê¸°íš|ìš´ì˜|ì˜ì—…|HR|ì¬ë¬´|ë²•ë¬´|ê°œë°œì|ë””ìì´ë„ˆ|ì—”ì§€ë‹ˆì–´|ë§¤ë‹ˆì €|ê¸°íšì|ì‚¬ì´ì–¸í‹°ìŠ¤íŠ¸)'
            import re
            has_job_pattern = bool(re.search(job_title_pattern, text))
            
            if not (has_job_keyword or has_job_pattern):
                if len(text) <= 15 and re.match(r'^[ê°€-í£a-zA-Z&\s]+$', text.strip()):
                    reasons.append("ì§§ì€ í…ìŠ¤íŠ¸ì´ì§€ë§Œ í—ˆìš© íŒ¨í„´")
                else:
                    reasons.append("í‚¤ì›Œë“œ/íŒ¨í„´ ì—†ìŒ")
            
            if reasons:
                print(f"    â†’ ì œê±° ì´ìœ : {', '.join(reasons)}")
        
        print(f"\n=== ìœ ì§€ëœ í•­ëª©ë“¤ (ì²˜ìŒ 10ê°œ) ===")
        for i, text in enumerate(filtered_texts[:10], 1):
            print(f"{i:2d}. {text[:100]}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
    finally:
        if driver:
            driver.quit()

if __name__ == "__main__":
    debug_toss_filtering()